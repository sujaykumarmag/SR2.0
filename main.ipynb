{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eadaea07",
   "metadata": {},
   "source": [
    "# SPEECH RECOGNITION AND TEXT TRANSFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1de3b",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8936291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "from os import path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os import walk\n",
    "from scipy import signal\n",
    "import wave\n",
    "import librosa \n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import normalize\n",
    "import soundfile as sf\n",
    "import noisereduce as nr \n",
    "from scipy.io import wavfile\n",
    "from pocketsphinx import AudioFile, get_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12b5ffb",
   "metadata": {},
   "source": [
    "## CONVERSION OF MP3 INTO WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21538619",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk('data'):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "f.remove('.DS_Store')   #FOR mac's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0dc4726",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0;\n",
    "for x in f:\n",
    "    input_file = 'data'+'/'+f[i]\n",
    "    i=i+1;\n",
    "    output_file = \"new_data/file\"+i.__str__()+\".wav\"\n",
    "    sound = AudioSegment.from_mp3(input_file)\n",
    "    sound.export(output_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77daa101",
   "metadata": {},
   "outputs": [],
   "source": [
    "datax = []\n",
    "for (dirpath, dirnames, filenames) in walk('new_data'):\n",
    "    datax.extend(filenames)\n",
    "    break\n",
    "datax.remove('.DS_Store')   #FOR mac's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271809e3",
   "metadata": {},
   "source": [
    "### Setting Up the Google Speech Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50b8732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "recognizer.energy_threshold = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f560b6",
   "metadata": {},
   "source": [
    "### Importing Audio files from the new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c5375cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for x in datax:\n",
    "    audio_ex = sr.AudioFile('new_data/'+x)\n",
    "    with audio_ex as source:\n",
    "        audiodata = recognizer.record(audio_ex)\n",
    "    data.append(audiodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "597ddc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = recognizer.recognize_google(\n",
    "#   audio_data = , \n",
    "#   language='en-US')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d16b5f",
   "metadata": {},
   "source": [
    "## PRE_PROCESSING OF AUDIO FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5de12cc",
   "metadata": {},
   "source": [
    "### Utility Functions for Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df05812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 200 # sample rate in Hz\n",
    "tau = 10 # time window in seconds for mean computation\n",
    "\n",
    "# Boxcar/SMA filter params\n",
    "N = int(tau*fs) # Number of samples corresponding to tau\n",
    "h_boxcar = np.ones(N)/N  # impulse response of boxcar filter\n",
    "\n",
    "# EMA filter params\n",
    "alpha = np.exp(-1/(fs*tau))\n",
    "a_ema = [1, -alpha] # Denominator\n",
    "b_ema =  1 - alpha # Numerator\n",
    "\n",
    "w, h = signal.freqz(h_boxcar)\n",
    "\n",
    "w, h = signal.freqz(b_ema, a_ema)\n",
    "\n",
    "# Using scipy's stft/istft function; see scipy's stft source code for details\n",
    "def audio_to_frames(y: np.array, m, hop_size, fs) -> np.array:\n",
    "    \"\"\"Convert y[n] into a matrix of frames Y_m(w) where each row is a time slice\"\"\"   \n",
    "    _, _, Zxx = signal.stft(y, fs=fs, nperseg=m, noverlap=hop_size, nfft=m*8)\n",
    "    return Zxx.T\n",
    "\n",
    "def frames_to_audio(Y: np.array, m, hop_size, fs) -> np.array:\n",
    "    \"\"\"Convert Y_m(w) matrix of frames into a 1D signal y[n] using Overlap-Add\"\"\"\n",
    "    _, xrec = signal.istft(Y.T, fs=fs, nperseg=m, noverlap=hop_size, nfft=m*8)\n",
    "    return xrec\n",
    "\n",
    "def spec_oversubtract(Y, est_Pn):\n",
    "    # Compute the alpha values for each frame\n",
    "    snr = 10*np.log10(sum(abs(Y)**2)/sum(est_Pn))\n",
    "    alpha = []\n",
    "    for gamma in snr:  # Implement the purple curve above\n",
    "        if gamma >= -5 and gamma <= 20:\n",
    "            a = -6.25*gamma/25 + 6\n",
    "            alpha.append(a)\n",
    "        elif gamma > 20:\n",
    "            alpha.append(1)\n",
    "        else:\n",
    "            alpha.append(7.25)\n",
    "    beta = 0.002\n",
    "    est_powX = np.maximum(abs(Y)**2 - alpha * est_Pn, beta * est_Pn) # Oversubtraction & spectral flooring\n",
    "    est_phaseX = np.angle(Y)\n",
    "    est_Sx = np.sqrt(est_powX) * np.exp(1j*est_phaseX)\n",
    "    return est_Sx\n",
    "def noise_estimation_snr(Y: np.array) -> (np.array, np.array):\n",
    "    \"\"\"Estimates the magnitude and power spectrum of the noise for each frame\"\"\"\n",
    "    \n",
    "    # Prepare the output variables\n",
    "    est_Mn = np.zeros(Y.shape)\n",
    "    est_Pn = np.zeros(Y.shape)\n",
    "    \n",
    "    N = 10 # Number of frames to use for estimating a-posteriori SNR\n",
    "    \n",
    "    # Iterate through each frame and estimate noise\n",
    "    for m in range(Y.shape[0]):\n",
    "        if m < N:\n",
    "            # Use noisy spectra for first 10 iterations\n",
    "            est_Mn[m] = abs(Y[m])\n",
    "            est_Pn[m] = est_Mn[m] ** 2\n",
    "        else:\n",
    "            a = 25\n",
    "            # A-posteriori SNR            \n",
    "            gammak = (abs(Y[m])**2)/np.mean(abs(Y[m-N:m])**2, axis=0) \n",
    "            alpha = 1/(1+np.exp(-a*(gammak-1.5)))\n",
    "            est_Mn[m] = alpha * abs(est_Mn[m-1]) + (1-alpha) * abs(Y[m])\n",
    "            est_Pn[m] = alpha * (abs(est_Mn[m-1])**2) + (1-alpha) * (abs(Y[m])**2)\n",
    "            \n",
    "    return est_Mn, est_Pn\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb12df7d",
   "metadata": {},
   "source": [
    "### Cleaning of Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2577edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(speech_file,noise_file):\n",
    "    x, fs = librosa.load(speech_file, sr=16000)\n",
    "    n, fs_noise = librosa.load(noise_file, sr=16000)\n",
    "\n",
    "    noise_gain = 0.7\n",
    "    n = noise_gain * n[:len(x)]\n",
    "\n",
    "    # Padding \n",
    "    for i in range(len(x)):\n",
    "        if(i>=len(n)):\n",
    "            n = np.append(n, [0])\n",
    "\n",
    "    y = x + n\n",
    "\n",
    "    # Compute the SNR for signal x to noise n\n",
    "    y_snr = 10*np.log10(np.sum(x**2)/np.sum(n**2))\n",
    "\n",
    "    win_t = 30e-3 # window size in seconds\n",
    "    win_s = round(fs*win_t) # window size in samples\n",
    "    hop_size = win_s//2\n",
    "\n",
    "    Y = audio_to_frames(y, win_s, hop_size, fs)\n",
    "    est_Mn, est_Pn = noise_estimation_snr(Y)\n",
    "    est_Sx_oversub = spec_oversubtract(Y, est_Pn)\n",
    "    x_hat_oversub = frames_to_audio(est_Sx_oversub, win_s, hop_size, fs)[:len(x)]\n",
    "    print(\"The File is processed\",x_hat_oversub,fs)\n",
    "    return x_hat_oversub,fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd5df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Denoising all the files from the new_data\n",
    "noise_file = 'noise.wav'\n",
    "i=0\n",
    "for file_name in datax:\n",
    "    denoised,fs=denoise(\"new_data/\"+file_name,noise_file)\n",
    "    i=i+1;\n",
    "    sf.write('processed_data/file'+i.__str__()+'.wav', denoised, fs)\n",
    "    rate, data = wavfile.read('processed_data/file'+i.__str__()+'.wav') \n",
    "    reduced_noise = nr.reduce_noise(y=data, sr=rate)\n",
    "    sf.write('processed_data/file'+i.__str__()+'.wav', denoised, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4139b31",
   "metadata": {},
   "source": [
    "## APPLYING CLASS LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c0a9c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.read_csv('data.csv',            \n",
    "            names=['audio_files', 'no_of_channels', 'frame_rate', 'sample_width','max_amplitude','no_of_ms'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d01de1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk('processed_data'):\n",
    "    f.extend(filenames)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd570216",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels =[]\n",
    "framerates =[]\n",
    "samplewidths = []\n",
    "framewidths =[]\n",
    "Ampmax = []\n",
    "framewidths = []\n",
    "size =[]\n",
    "f.remove('.DS_Store')\n",
    "for i in f:\n",
    "    x = AudioSegment.from_file('processed_data/'+i,format='wav')\n",
    "    channels.append(x.channels)\n",
    "    framerates.append(x.frame_rate)\n",
    "    samplewidths.append(x.sample_width)\n",
    "    framewidths.append(x.frame_width)\n",
    "    Ampmax.append(x.max)\n",
    "    size.append(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f047f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['audio_files'] = f\n",
    "df['no_of_channels'] = channels\n",
    "df['frame_rate'] = framerates\n",
    "df['sample_width'] = samplewidths\n",
    "df['max_amplitude']= Ampmax\n",
    "df['no_of_ms'] = size\n",
    "df['frame_width'] = framewidths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0c2cd01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in f:\n",
    "    x = AudioSegment.from_file('processed_data/'+i,format='wav')\n",
    "    x+160\n",
    "    normalize(x)\n",
    "    x.export('pre_processed_data/'+i,format='wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c8d701",
   "metadata": {},
   "source": [
    "## APPLYING THE CMU TRANSCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e56c9de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions = []\n",
    "for i in f:\n",
    "    for phrase in AudioFile('processed_data/'+i): \n",
    "        transcriptions.append(str(phrase))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c7082844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"an odd a are you don't fool to come out as on you not like no a you aren't in use\",\n",
       " \"and our lord and ah so and all my own greed or or you could do that are and or get an could are you you can dot org and when i ordered a boat or what are totally get out i the the don't know go that order will do what you had or what at read like you got owen owen and who we go an attitude you eat or two who on or what about the pet op words a dumpster the and ah the to and old old old cunt a and the the\"]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "80698eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cmu_transcriptions'] = transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b72dd0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9793fd9",
   "metadata": {},
   "source": [
    "### APPLYING THE [PAUSE] IN THE TRANSCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "87028899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(file, start_time, end_time):\n",
    "    sample_rate, data = wavfile.read(file)\n",
    "    start_point = int(sample_rate * start_time / 1000)\n",
    "    end_point = int(sample_rate * end_time / 1000)\n",
    "    length = (end_time - start_time) / 1000\n",
    "    counter = 0\n",
    "    for i in range(start_point, end_point):\n",
    "        if data[i] < 0 and data[i+1] > 0:\n",
    "            counter += 1\n",
    "    return counter/length    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "50f627f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676.0869565217391"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq(\"stereo_file1.wav\", 0 ,41400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5391a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
